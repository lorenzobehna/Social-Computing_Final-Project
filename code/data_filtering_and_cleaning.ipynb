{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:54:14.122073300Z",
     "start_time": "2024-05-21T15:54:14.110872500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import demoji\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect, DetectorFactory\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:56:21.341020700Z",
     "start_time": "2024-05-21T15:56:21.184170100Z"
    }
   },
   "outputs": [],
   "source": [
    "df_comments = pd.read_pickle(\"../data/comments/all_comments.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:56:25.565644300Z",
     "start_time": "2024-05-21T15:56:23.171497400Z"
    }
   },
   "outputs": [],
   "source": [
    "# converting strings to datetime\n",
    "df_comments['video_publish_date'] = pd.to_datetime(df_comments['video_publish_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "df_comments['comment_publish_date'] = pd.to_datetime(df_comments['comment_publish_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# Extracting year, and month from the datetime column\n",
    "# video\n",
    "df_comments['video_year'] = df_comments['video_publish_date'].dt.year\n",
    "df_comments['video_month'] = df_comments['video_publish_date'].dt.month\n",
    "\n",
    "# comment\n",
    "df_comments['comment_year'] = df_comments['comment_publish_date'].dt.year\n",
    "df_comments['comment_month'] = df_comments['comment_publish_date'].dt.month\n",
    "\n",
    "# define the fixed minimum date\n",
    "min_date = pd.to_datetime('2017-01-01')\n",
    "\n",
    "# Calculate the running month\n",
    "df_comments['video_running_month'] = df_comments['video_month'] + 12 * (df_comments['video_year'] - df_comments['video_year'].min())\n",
    "df_comments['comment_running_month'] = df_comments['comment_month'] + 12 * (df_comments['comment_year'] - df_comments['comment_year'].min())\n",
    "\n",
    "# Calculate the running days\n",
    "df_comments['comment_running_days'] = (df_comments['comment_publish_date'] - min_date).dt.days\n",
    "\n",
    "# filter comments after 90 days of videos' release\n",
    "# Calculate the difference in days\n",
    "df_comments['days_publish_date_difference'] = (df_comments['comment_publish_date'] - df_comments['video_publish_date']).dt.days\n",
    "\n",
    "# Filter to include only comments within 90 days of the video publish date\n",
    "df_timely_comments = df_comments[df_comments['days_publish_date_difference'] <= 90]\n",
    "\n",
    "df_timely_comments = df_timely_comments.drop(columns='days_publish_date_difference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timely_comments.to_pickle(\"../data/comments/timely_comments.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:56:31.157317Z",
     "start_time": "2024-05-21T15:56:31.135246400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to count words in a string\n",
    "def word_count(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:56:42.964841700Z",
     "start_time": "2024-05-21T15:56:42.888964400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out comments with less than 3 words\n",
    "df_timely_comments = df_timely_comments[df_timely_comments['comment_text'].apply(word_count) >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:56:44.707991200Z",
     "start_time": "2024-05-21T15:56:44.479359200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19402 entries, 84 to 77797\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   video_id               19402 non-null  object        \n",
      " 1   video_title            19402 non-null  object        \n",
      " 2   video_publish_date     19402 non-null  datetime64[ns]\n",
      " 3   video_category_id      19402 non-null  object        \n",
      " 4   comment_text           19402 non-null  object        \n",
      " 5   comment_id             19402 non-null  object        \n",
      " 6   comment_publish_date   19402 non-null  datetime64[ns]\n",
      " 7   video_year             19402 non-null  int32         \n",
      " 8   video_month            19402 non-null  int32         \n",
      " 9   comment_year           19402 non-null  int32         \n",
      " 10  comment_month          19402 non-null  int32         \n",
      " 11  video_running_month    19402 non-null  int32         \n",
      " 12  comment_running_month  19402 non-null  int32         \n",
      " 13  comment_running_days   19402 non-null  int64         \n",
      "dtypes: datetime64[ns](2), int32(6), int64(1), object(5)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_publish_date</th>\n",
       "      <th>video_category_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_publish_date</th>\n",
       "      <th>video_year</th>\n",
       "      <th>video_month</th>\n",
       "      <th>comment_year</th>\n",
       "      <th>comment_month</th>\n",
       "      <th>video_running_month</th>\n",
       "      <th>comment_running_month</th>\n",
       "      <th>comment_running_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Bg_tJvCA8zw</td>\n",
       "      <td>Tonight Showbotics: Jimmy Meets Sophia the Hum...</td>\n",
       "      <td>2017-04-26 03:57:12</td>\n",
       "      <td>23</td>\n",
       "      <td>We laugh at Sofia now, but is just a matter of...</td>\n",
       "      <td>Uggx5fEEMrzsYHgCoAEC</td>\n",
       "      <td>2017-04-26 10:35:26</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Bg_tJvCA8zw</td>\n",
       "      <td>Tonight Showbotics: Jimmy Meets Sophia the Hum...</td>\n",
       "      <td>2017-04-26 03:57:12</td>\n",
       "      <td>23</td>\n",
       "      <td>&amp;quot;stay in your lane girl&amp;quot; strikes aga...</td>\n",
       "      <td>UggnYKq-trQl63gCoAEC</td>\n",
       "      <td>2017-04-26 11:22:16</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Bg_tJvCA8zw</td>\n",
       "      <td>Tonight Showbotics: Jimmy Meets Sophia the Hum...</td>\n",
       "      <td>2017-04-26 03:57:12</td>\n",
       "      <td>23</td>\n",
       "      <td>&amp;quot;this is a good begining of my plan to do...</td>\n",
       "      <td>Ugif2hNhsM8WEngCoAEC</td>\n",
       "      <td>2017-05-04 01:46:28</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Bg_tJvCA8zw</td>\n",
       "      <td>Tonight Showbotics: Jimmy Meets Sophia the Hum...</td>\n",
       "      <td>2017-04-26 03:57:12</td>\n",
       "      <td>23</td>\n",
       "      <td>&amp;quot;Do you know where you are Sophia?&amp;quot;&lt;...</td>\n",
       "      <td>Ugjd-6BJCDwa4ngCoAEC</td>\n",
       "      <td>2017-07-04 00:42:58</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Bg_tJvCA8zw</td>\n",
       "      <td>Tonight Showbotics: Jimmy Meets Sophia the Hum...</td>\n",
       "      <td>2017-04-26 03:57:12</td>\n",
       "      <td>23</td>\n",
       "      <td>this was totally cool...but Sophia was a littl...</td>\n",
       "      <td>UgilTmlEk2XHo3gCoAEC</td>\n",
       "      <td>2017-04-26 04:01:05</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77789</th>\n",
       "      <td>ABHz5oZx-WA</td>\n",
       "      <td>I Asked AI about the Second Coming of Jesus, a...</td>\n",
       "      <td>2023-06-05 22:33:59</td>\n",
       "      <td>27</td>\n",
       "      <td>I found the info in this video interesting and...</td>\n",
       "      <td>UgzGWD7FVNAgABr3FJx4AaABAg</td>\n",
       "      <td>2023-06-12 13:31:20</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77792</th>\n",
       "      <td>ABHz5oZx-WA</td>\n",
       "      <td>I Asked AI about the Second Coming of Jesus, a...</td>\n",
       "      <td>2023-06-05 22:33:59</td>\n",
       "      <td>27</td>\n",
       "      <td>If you&amp;#39;re that impressed by the humanoid r...</td>\n",
       "      <td>Ugy8XkAGvtdD8r9sbj14AaABAg</td>\n",
       "      <td>2023-07-19 16:33:28</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>2390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77793</th>\n",
       "      <td>ABHz5oZx-WA</td>\n",
       "      <td>I Asked AI about the Second Coming of Jesus, a...</td>\n",
       "      <td>2023-06-05 22:33:59</td>\n",
       "      <td>27</td>\n",
       "      <td>While I do appreciate the story here, there ar...</td>\n",
       "      <td>UgyGST9Bzhl2K-5fB_R4AaABAg</td>\n",
       "      <td>2023-06-22 21:06:31</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77796</th>\n",
       "      <td>ABHz5oZx-WA</td>\n",
       "      <td>I Asked AI about the Second Coming of Jesus, a...</td>\n",
       "      <td>2023-06-05 22:33:59</td>\n",
       "      <td>27</td>\n",
       "      <td>I wanted to share this experience I had a few ...</td>\n",
       "      <td>UgwI1EYOxa1-0E7TGWR4AaABAg</td>\n",
       "      <td>2023-07-08 01:01:37</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>2379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77797</th>\n",
       "      <td>ABHz5oZx-WA</td>\n",
       "      <td>I Asked AI about the Second Coming of Jesus, a...</td>\n",
       "      <td>2023-06-05 22:33:59</td>\n",
       "      <td>27</td>\n",
       "      <td>Thank you for this wonderful video! I have inc...</td>\n",
       "      <td>UgwSgOcgXH8S3bB0K2l4AaABAg</td>\n",
       "      <td>2023-06-11 19:16:27</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19402 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          video_id                                        video_title  \\\n",
       "84     Bg_tJvCA8zw  Tonight Showbotics: Jimmy Meets Sophia the Hum...   \n",
       "87     Bg_tJvCA8zw  Tonight Showbotics: Jimmy Meets Sophia the Hum...   \n",
       "103    Bg_tJvCA8zw  Tonight Showbotics: Jimmy Meets Sophia the Hum...   \n",
       "114    Bg_tJvCA8zw  Tonight Showbotics: Jimmy Meets Sophia the Hum...   \n",
       "115    Bg_tJvCA8zw  Tonight Showbotics: Jimmy Meets Sophia the Hum...   \n",
       "...            ...                                                ...   \n",
       "77789  ABHz5oZx-WA  I Asked AI about the Second Coming of Jesus, a...   \n",
       "77792  ABHz5oZx-WA  I Asked AI about the Second Coming of Jesus, a...   \n",
       "77793  ABHz5oZx-WA  I Asked AI about the Second Coming of Jesus, a...   \n",
       "77796  ABHz5oZx-WA  I Asked AI about the Second Coming of Jesus, a...   \n",
       "77797  ABHz5oZx-WA  I Asked AI about the Second Coming of Jesus, a...   \n",
       "\n",
       "       video_publish_date video_category_id  \\\n",
       "84    2017-04-26 03:57:12                23   \n",
       "87    2017-04-26 03:57:12                23   \n",
       "103   2017-04-26 03:57:12                23   \n",
       "114   2017-04-26 03:57:12                23   \n",
       "115   2017-04-26 03:57:12                23   \n",
       "...                   ...               ...   \n",
       "77789 2023-06-05 22:33:59                27   \n",
       "77792 2023-06-05 22:33:59                27   \n",
       "77793 2023-06-05 22:33:59                27   \n",
       "77796 2023-06-05 22:33:59                27   \n",
       "77797 2023-06-05 22:33:59                27   \n",
       "\n",
       "                                            comment_text  \\\n",
       "84     We laugh at Sofia now, but is just a matter of...   \n",
       "87     &quot;stay in your lane girl&quot; strikes aga...   \n",
       "103    &quot;this is a good begining of my plan to do...   \n",
       "114    &quot;Do you know where you are Sophia?&quot;<...   \n",
       "115    this was totally cool...but Sophia was a littl...   \n",
       "...                                                  ...   \n",
       "77789  I found the info in this video interesting and...   \n",
       "77792  If you&#39;re that impressed by the humanoid r...   \n",
       "77793  While I do appreciate the story here, there ar...   \n",
       "77796  I wanted to share this experience I had a few ...   \n",
       "77797  Thank you for this wonderful video! I have inc...   \n",
       "\n",
       "                       comment_id comment_publish_date  video_year  \\\n",
       "84           Uggx5fEEMrzsYHgCoAEC  2017-04-26 10:35:26        2017   \n",
       "87           UggnYKq-trQl63gCoAEC  2017-04-26 11:22:16        2017   \n",
       "103          Ugif2hNhsM8WEngCoAEC  2017-05-04 01:46:28        2017   \n",
       "114          Ugjd-6BJCDwa4ngCoAEC  2017-07-04 00:42:58        2017   \n",
       "115          UgilTmlEk2XHo3gCoAEC  2017-04-26 04:01:05        2017   \n",
       "...                           ...                  ...         ...   \n",
       "77789  UgzGWD7FVNAgABr3FJx4AaABAg  2023-06-12 13:31:20        2023   \n",
       "77792  Ugy8XkAGvtdD8r9sbj14AaABAg  2023-07-19 16:33:28        2023   \n",
       "77793  UgyGST9Bzhl2K-5fB_R4AaABAg  2023-06-22 21:06:31        2023   \n",
       "77796  UgwI1EYOxa1-0E7TGWR4AaABAg  2023-07-08 01:01:37        2023   \n",
       "77797  UgwSgOcgXH8S3bB0K2l4AaABAg  2023-06-11 19:16:27        2023   \n",
       "\n",
       "       video_month  comment_year  comment_month  video_running_month  \\\n",
       "84               4          2017              4                    4   \n",
       "87               4          2017              4                    4   \n",
       "103              4          2017              5                    4   \n",
       "114              4          2017              7                    4   \n",
       "115              4          2017              4                    4   \n",
       "...            ...           ...            ...                  ...   \n",
       "77789            6          2023              6                   78   \n",
       "77792            6          2023              7                   78   \n",
       "77793            6          2023              6                   78   \n",
       "77796            6          2023              7                   78   \n",
       "77797            6          2023              6                   78   \n",
       "\n",
       "       comment_running_month  comment_running_days  \n",
       "84                         4                   115  \n",
       "87                         4                   115  \n",
       "103                        5                   123  \n",
       "114                        7                   184  \n",
       "115                        4                   115  \n",
       "...                      ...                   ...  \n",
       "77789                     78                  2353  \n",
       "77792                     79                  2390  \n",
       "77793                     78                  2363  \n",
       "77796                     79                  2379  \n",
       "77797                     78                  2352  \n",
       "\n",
       "[19402 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_timely_comments.info()\n",
    "df_timely_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:57:08.962608500Z",
     "start_time": "2024-05-21T15:57:08.955632500Z"
    }
   },
   "outputs": [],
   "source": [
    "# text cleaning functions\n",
    "\n",
    "# remove all emojis\n",
    "def remove_emojis(text):\n",
    "    return demoji.replace(text, \"\")\n",
    "\n",
    "# Function to normalize text (NOTE: If creating R dataframe, comment out the # Remove punctuations part)\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \" \", text)  # Remove @mentions\n",
    "    text = re.sub(r\"&quot;\", \"\", text) # Remove instances of &quot;\n",
    "    text = re.sub(r\"&#39;\", \"'\", text) # Replace all instances of &#39; with '\n",
    "    text = re.sub(r\"<[^>]*>\", \" \", text) # Remove all HTML tags\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", \" \", text)  # Remove URLs\n",
    "    text = re.sub(r\"https?\", \" \", text)  # Remove http/https\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)  # Remove repeated characters\n",
    "    #text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n",
    "    return text\n",
    "\n",
    "# Function to correct spelling errors \n",
    "def correct_spelling(text):\n",
    "    blob = TextBlob(text)\n",
    "    corrected_text = blob.correct()\n",
    "    return str(corrected_text)\n",
    "\n",
    "# collect all the stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to detect if language is English\n",
    "# ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    words = text.split()\n",
    "    # if word is not in stop_words, append it to the list and lower the words\n",
    "    filtered_words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    joined_words = ' '.join(filtered_words)\n",
    "    \n",
    "    return joined_words\n",
    "\n",
    "# test on small data\n",
    "#text = 'Hey, there is no such thing like bubble tea'\n",
    "#remove_stop_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:57:46.877396100Z",
     "start_time": "2024-05-21T15:57:10.805676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply text cleaning functions (NOTE: If creating R Dataframe comment out the applicaton of remove_stop_words())\n",
    "df_timely_comments['comment_text'] = df_timely_comments['comment_text'].apply(remove_emojis)\n",
    "df_timely_comments['comment_text'] = df_timely_comments['comment_text'].apply(normalize_text)\n",
    "df_timely_comments['comment_text'] = df_timely_comments['comment_text'].apply(correct_spelling)\n",
    "\n",
    "#df_timely_comments['comment_text'] = df_timely_comments['comment_text'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84       He laugh at Sofa now, but is just a mater of t...\n",
      "103      this is a god beginning of my plan to dominate...\n",
      "114      To you know where you are Sophia? I'm in a dream.\n",
      "115      this was total col.but Sophia was a little bit...\n",
      "122               It 4:58 why do people think it's a joke.\n",
      "                               ...                        \n",
      "77789    I found the into in this video interesting and...\n",
      "77792    Of you're that impressed by the humanoid root ...\n",
      "77793    While I do appreciate the story here, there ar...\n",
      "77796    I wanted to share this experience I had a few ...\n",
      "77797    Thank you for this wonderful video! I have inj...\n",
      "Name: comment_text, Length: 18654, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_colwidth', None)  # Set the max column width to unlimited\n",
    "# Apply the is_english() function to the 'comment_text' column\n",
    "df_timely_comments = df_timely_comments[df_timely_comments['comment_text'].apply(is_english)]\n",
    "print(df_timely_comments['comment_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_timely_comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_filter1_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mdf_timely_comments\u001b[49m\n\u001b[1;32m      2\u001b[0m df_filter1_cleaned\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/comments/filter1_cleaned_comments.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_timely_comments' is not defined"
     ]
    }
   ],
   "source": [
    "df_filter1_cleaned = df_timely_comments\n",
    "df_filter1_cleaned.to_pickle(\"../data/comments/filter1_cleaned_comments.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter1_cleaned = pd.read_pickle(\"../data/comments/filter1_cleaned_comments.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your Pandas DataFrame is named 'df'\n",
    "# pandas2ri.activate()\n",
    "\n",
    "# r_dataframe = pandas2ri.py2ri(df_filter1_cleaned)\n",
    "\n",
    "# Save the R DataFrame to an RData file\n",
    "#ro.r['save'](r_dataframe, file=\"../data/comments/R/data.RData\")\n",
    "\n",
    "df_filter1_cleaned.to_csv(\"../data/comments/R/data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18654 entries, 84 to 77797\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   video_id               18654 non-null  object        \n",
      " 1   video_title            18654 non-null  object        \n",
      " 2   video_publish_date     18654 non-null  datetime64[ns]\n",
      " 3   video_category_id      18654 non-null  object        \n",
      " 4   comment_text           18654 non-null  object        \n",
      " 5   comment_id             18654 non-null  object        \n",
      " 6   comment_publish_date   18654 non-null  datetime64[ns]\n",
      " 7   video_year             18654 non-null  int32         \n",
      " 8   video_month            18654 non-null  int32         \n",
      " 9   comment_year           18654 non-null  int32         \n",
      " 10  comment_month          18654 non-null  int32         \n",
      " 11  video_running_month    18654 non-null  int32         \n",
      " 12  comment_running_month  18654 non-null  int32         \n",
      " 13  comment_running_days   18654 non-null  int64         \n",
      "dtypes: datetime64[ns](2), int32(6), int64(1), object(5)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_filter1_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Text with Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:58:49.145873700Z",
     "start_time": "2024-05-21T15:58:49.135053200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define AI-related keywords\n",
    "ai_keywords = ['artificial intelligence', 'machine learning', 'neural networks', 'deep learning', 'automation', 'ai', 'a.i.', 'robot', 'sophia', 'gpt', 'bard', 'gemini', 'ml', 'big data', 'large language model', 'natural language processing', 'augmented intelligence', 'prompt', 'chatgpt', 'dalee', 'stabel diffusion', 'bot', 'terminator', 'skynet']\n",
    "# Function to check if comment contains any AI-related keywords\n",
    "def contains_keywords(text):\n",
    "    return any(keyword in text.lower() for keyword in ai_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114      To you know where you are Sophia? I'm in a dream.\n",
      "115      this was total col.but Sophia was a little bit...\n",
      "130      when she said His is a god beginning of my pla...\n",
      "135                     Sophia is the start of termination\n",
      "158      Puny how humans can be so afraid of what they ...\n",
      "                               ...                        \n",
      "77777    His is going to be a big problem when of advan...\n",
      "77780    I enjoyed this video. The video made me believ...\n",
      "77792    Of you're that impressed by the humanoid root ...\n",
      "77793    While I do appreciate the story here, there ar...\n",
      "77796    I wanted to share this experience I had a few ...\n",
      "Name: comment_text, Length: 4973, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filter comments containing AI-related keywords\n",
    "\n",
    "df_test = df_filter1_cleaned[df_filter1_cleaned['comment_text'].apply(contains_keywords)]  \n",
    "\n",
    "#print(df_filter1_cleaned['comment_text_keyword_filtered'])\n",
    "\n",
    "print(df_test['comment_text'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".soco_virtual_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
