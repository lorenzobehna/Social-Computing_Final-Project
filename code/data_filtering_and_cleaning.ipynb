{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:54:14.122073300Z",
     "start_time": "2024-05-21T15:54:14.110872500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import demoji\n",
    "from langdetect import detect, DetectorFactory\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:56:21.341020700Z",
     "start_time": "2024-05-21T15:56:21.184170100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading in the comments dataframe\n",
    "df_comments = pd.read_pickle(\"../data/comments/all_comments.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:56:25.565644300Z",
     "start_time": "2024-05-21T15:56:23.171497400Z"
    }
   },
   "outputs": [],
   "source": [
    "# converting strings to datetime\n",
    "df_comments['video_publish_date'] = pd.to_datetime(df_comments['video_publish_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "df_comments['comment_publish_date'] = pd.to_datetime(df_comments['comment_publish_date'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# Extracting year, and month from the datetime column\n",
    "# video\n",
    "df_comments['video_year'] = df_comments['video_publish_date'].dt.year\n",
    "df_comments['video_month'] = df_comments['video_publish_date'].dt.month\n",
    "\n",
    "# comment\n",
    "df_comments['comment_year'] = df_comments['comment_publish_date'].dt.year\n",
    "df_comments['comment_month'] = df_comments['comment_publish_date'].dt.month\n",
    "\n",
    "# define the fixed minimum date\n",
    "min_date = pd.to_datetime('2017-01-01')\n",
    "\n",
    "# Calculate the running month\n",
    "df_comments['video_running_month'] = df_comments['video_month'] + 12 * (df_comments['video_year'] - min_date.year)\n",
    "df_comments['comment_running_month'] = df_comments['comment_month'] + 12 * (df_comments['comment_year'] - min_date.year)\n",
    "\n",
    "# Calculate the running days\n",
    "df_comments['comment_running_days'] = (df_comments['comment_publish_date'] - min_date).dt.days\n",
    "\n",
    "# filter comments after 90 days of videos' release\n",
    "# Calculate the difference in days\n",
    "df_comments['days_publish_date_difference'] = (df_comments['comment_publish_date'] - df_comments['video_publish_date']).dt.days\n",
    "\n",
    "# Filter to include only comments within 90 days of the video publish date\n",
    "df_timely_comments = df_comments[df_comments['days_publish_date_difference'] <= 90]\n",
    "\n",
    "df_timely_comments = df_timely_comments.drop(columns='days_publish_date_difference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only timely comments to pickle format\n",
    "df_timely_comments.to_pickle(\"../data/comments/timely_comments.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:56:31.157317Z",
     "start_time": "2024-05-21T15:56:31.135246400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to count words in a string\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# Filter out comments with less than 3 words\n",
    "df_timely_comments = df_timely_comments[df_timely_comments['comment_text'].apply(word_count) >= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:57:08.962608500Z",
     "start_time": "2024-05-21T15:57:08.955632500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text Cleaning Functions\n",
    "\n",
    "# remove all emojis\n",
    "def remove_emojis(text):\n",
    "    return demoji.replace(text, \"\")\n",
    "\n",
    "# Function to normalize text (NOTE: If creating R dataframe, comment out the # Remove punctuations part)\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \" \", text)  # Remove @mentions\n",
    "    text = re.sub(r\"&quot;\", \"\", text) # Remove instances of &quot;\n",
    "    text = re.sub(r\"&#39;\", \"'\", text) # Replace all instances of &#39; with '\n",
    "    text = re.sub(r\"<[^>]*>\", \" \", text) # Remove all HTML tags\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", \" \", text)  # Remove URLs\n",
    "    text = re.sub(r\"https?\", \" \", text)  # Remove http/https\n",
    "    text = re.sub(r'(.)\\1+', r'\\1', text)  # Remove repeated characters\n",
    "    #text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n",
    "    return text\n",
    "\n",
    "# Function to detect if language is English\n",
    "# ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:57:46.877396100Z",
     "start_time": "2024-05-21T15:57:10.805676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply text cleaning functions \n",
    "df_timely_comments['comment_text'] = df_timely_comments['comment_text'].apply(remove_emojis)\n",
    "df_timely_comments['comment_text'] = df_timely_comments['comment_text'].apply(normalize_text)\n",
    "df_timely_comments = df_timely_comments[df_timely_comments['comment_text'].apply(is_english)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising descriptive comment word count analysis (**before** keyword filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of words per comment\n",
    "df_descriptive_analysis = df_timely_comments\n",
    "df_descriptive_analysis['word_count'] = df_descriptive_analysis['comment_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot the histogram of the distribution of word length\n",
    "plt.hist(df_descriptive_analysis['word_count'], bins=range(1, 200), edgecolor='black')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Word Counts per Text Entry')\n",
    "plt.show()\n",
    "\n",
    "# Plot a boxplot showing mean, median and quartiles of comment length as well as outliers\n",
    "plt.boxplot(df_descriptive_analysis['word_count'], patch_artist=True, showfliers=False)\n",
    "\n",
    "# Customize x-axis labels\n",
    "max_word_count = df_descriptive_analysis['word_count'].max()\n",
    "plt.yticks(range(0, max_word_count + 10, 10))\n",
    "plt.ylim(0, 80)\n",
    "# Remove y-axis labels\n",
    "plt.xticks([])\n",
    "\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Boxplot of Comment Length Without Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store cleaned and timely data in a new df and save it \n",
    "df_filtered_text_cleaned = df_timely_comments\n",
    "df_filtered_text_cleaned.to_pickle(\"../data/comments/df-filtered_text-cleaned_comments.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the dataframe can be loaded in if needed\n",
    "df_filtered_text_cleaned = pd.read_pickle(\"../data/comments/df-filtered_text-cleaned_comments.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Text with Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:58:49.145873700Z",
     "start_time": "2024-05-21T15:58:49.135053200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define AI-related keywords\n",
    "ai_keywords = [\n",
    "    'artificial intelligence', 'ai', 'a.i.', 'a.i', 'a. i', 'a i.', 'a i', 'machine learning', 'ml', \n",
    "    'deep learning', 'neural networks', 'large language model', 'language model', 'supervised learning', \n",
    "    'unsupervised learning', 'self-driving', 'self driving', 'image recognition', 'speech recognition', \n",
    "    'automation', 'turing test', 'agi', 'artificial general intelligence', 'ani', 'artificial narrow intelligence', \n",
    "    'asi', 'artificial superintelligence', 'algorithm', 'intelligent agent', 'data mining', 'data science', \n",
    "    'computer science', 'intelligent system', 'predictive modeling', 'quantum computing', 'virtual assistant', \n",
    "    'bot', 'robot', 'gpt', 'bard', 'gemini', 'chatgpt', 'transformer', 'openai', 'dalle', 'stable diffusion', \n",
    "    'meta', 'microsoft', 'siri', 'technology', 'terminator', 'skynet', 'prompt', 'copilot'\n",
    "]\n",
    "\n",
    "# Compile regular expressions for all keywords with word boundaries\n",
    "keyword_patterns = [re.compile(r'\\b' + re.escape(keyword) + r'\\b', re.IGNORECASE) for keyword in ai_keywords]\n",
    "\n",
    "# Function to check if comment contains any AI-related keywords\n",
    "def contains_keywords(text):\n",
    "    return any(pattern.search(text) for pattern in keyword_patterns)\n",
    "    #return any(keyword.lower() in text.lower() for keyword in ai_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter comments containing AI-related keywords\n",
    "df_filtered_text_keywordfiltered_and_cleaned = df_filtered_text_cleaned[df_filtered_text_cleaned['comment_text'].apply(contains_keywords)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered (1) Dataframe to CSV \n",
    "df_filtered_text_keywordfiltered_and_cleaned.to_csv(\"../data/comments/R/filtered_and_cleaned_comments.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising descriptive comment word count analysis (**after** keyword filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of words per comment\n",
    "df_filtered_text_descriptive = df_filtered_text_keywordfiltered_and_cleaned\n",
    "df_filtered_text_descriptive['word_count'] = df_filtered_text_descriptive['comment_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plot the histogram of the distribution of word length\n",
    "plt.hist(df_filtered_text_descriptive['word_count'], bins=range(1, 200), edgecolor='black')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Word Counts per Text Entry')\n",
    "plt.show()\n",
    "\n",
    "# Plot a boxplot showing mean, median and quartiles of comment length as well as outliers\n",
    "plt.boxplot(df_filtered_text_descriptive['word_count'], patch_artist=True, showfliers=False)\n",
    "\n",
    "# Customize x-axis labels\n",
    "max_word_count = df_filtered_text_descriptive['word_count'].max()\n",
    "plt.yticks(range(0, max_word_count + 10, 10))\n",
    "plt.ylim(0, 150)\n",
    "# Remove y-axis labels\n",
    "plt.xticks([])\n",
    "\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Boxplot of Comment Length Without Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Word Lenght and P-Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptive_analysis['word_count'] = df_descriptive_analysis['comment_text'].apply(lambda x: len(x.split()))\n",
    "df_filtered_text_descriptive['word_count'] = df_filtered_text_descriptive['comment_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "mean_word_count_all = df_descriptive_analysis['word_count'].mean()\n",
    "mean_word_count_filtered = df_filtered_text_descriptive['word_count'].mean()\n",
    "\n",
    "std_word_count_all = df_descriptive_analysis['word_count'].std()\n",
    "std_word_count_filtered = df_filtered_text_descriptive['word_count'].std()\n",
    "\n",
    "# Perfomr t-test\n",
    "t_stat, p_value = ttest_ind(df_descriptive_analysis['word_count'], df_filtered_text_descriptive['word_count'], equal_var=False)\n",
    "\n",
    "# Display the results\n",
    "print(f'Mean Word Count for All Comments: {mean_word_count_all:.2f}')\n",
    "print(f'Standard Deviation for All Comments: {std_word_count_all:.2f}')\n",
    "print(f'Mean Word Count for Filtered Comments: {mean_word_count_filtered:.2f}')\n",
    "print(f'Standard Deviation for Filtered Comments: {std_word_count_filtered:.2f}')\n",
    "print(f'T-statistic: {t_stat:.2f}')\n",
    "print(f'P-value: {p_value}')\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('The difference in mean word counts between the two groups is statistically significant.')\n",
    "else:\n",
    "    print('The difference in mean word counts between the two groups is not statistically significant.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".soco_virtual_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
