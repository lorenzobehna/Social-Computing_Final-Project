{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "MAX_RESULTS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API Key: Lorenzo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the text file containing the API key\n",
    "with open(\"../authentication/YouTube_Data_API_Key.txt\", \"r\") as file:\n",
    "    API_KEY = file.read().strip() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API Key: Ishwarya**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the text file containing the API key\n",
    "with open(\"YOUR PATH TO THE API KEY HERE\", \"r\") as file:\n",
    "    API_KEY = file.read().strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to search for videos given a specific query. Requires max_results, published_after, and published_before both in datetime format\n",
    "def search_videos(query, max_results=MAX_RESULTS, published_after=None, published_before=None):\n",
    "    youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "    # convert datetime objects to ISO 8601 string format\n",
    "    published_after_string = published_after.strftime('%Y-%m-%dT%H:%M:%SZ') if published_after else None\n",
    "    published_before_string = published_before.strftime('%Y-%m-%dT%H:%M:%SZ') if published_before else None\n",
    "\n",
    "    ## Two requests are created, to separately search for medium and long lenght videos.\n",
    "    ## This ensures that we don't collect and YouTube Shorts videos, which we are not interested in.\n",
    "\n",
    "    # construct request for medium lenght videos\n",
    "    search_request_medium = youtube.search().list(\n",
    "        q=query, \n",
    "        part=\"snippet\", \n",
    "        type=\"video\", \n",
    "        maxResults=max_results, \n",
    "        order=\"viewCount\",\n",
    "        videoDuration=\"medium\", \n",
    "        publishedAfter=published_after_string, \n",
    "        publishedBefore=published_before_string)\n",
    "    \n",
    "    # construct request for long videos\n",
    "    search_request_long = youtube.search().list(\n",
    "        q=query, \n",
    "        part=\"snippet\", \n",
    "        type=\"video\", \n",
    "        maxResults=max_results, \n",
    "        order=\"viewCount\",\n",
    "        videoDuration=\"long\", \n",
    "        publishedAfter=published_after_string, \n",
    "        publishedBefore=published_before_string)\n",
    "    \n",
    "    # execute both search requests and store the response\n",
    "    search_response_medium = search_request_medium.execute()\n",
    "    search_response_long = search_request_long.execute()\n",
    "\n",
    "    # save video IDs into lists\n",
    "    video_ids_medium = [item['id']['videoId'] for item in search_response_medium['items']]\n",
    "    video_ids_long = [item['id']['videoId'] for item in search_response_long['items']]\n",
    "\n",
    "    # construct request to retrieve data about found videos\n",
    "    video_request_medium = youtube.videos().list(part=\"snippet,statistics\", id=\",\".join(video_ids_medium))\n",
    "    video_request_long = youtube.videos().list(part=\"snippet,statistics\", id=\",\".join(video_ids_long))\n",
    "\n",
    "    # execute both video requests and store the response\n",
    "    video_response_medium = video_request_medium.execute()\n",
    "    video_response_long = video_request_long.execute()\n",
    "\n",
    "    # create empty list videos_data, in which each list item is a dictionary of metadata about one video\n",
    "    videos_data = []\n",
    "    # loop through the medium length videos and append to videos_data\n",
    "    for item in video_response_medium['items']:\n",
    "        videos_data.append({\n",
    "            'title': item['snippet']['title'],\n",
    "            'publish_date': item['snippet']['publishedAt'],\n",
    "            'description': item['snippet']['description'],\n",
    "            'video_id': item['id'],\n",
    "            'view_count': int(item['statistics']['viewCount']) if 'viewCount' in item['statistics'] else 0\n",
    "        })\n",
    "    # loop through the long videos and append to videos_data\n",
    "    for item in video_response_long['items']:\n",
    "        videos_data.append({\n",
    "            'title': item['snippet']['title'],\n",
    "            'publish_date': item['snippet']['publishedAt'],\n",
    "            'description': item['snippet']['description'],\n",
    "            'video_id': item['id'],\n",
    "            'view_count': int(item['statistics']['viewCount']) if 'viewCount' in item['statistics'] else 0\n",
    "        })\n",
    "    # convert the list of dictionaries to a dataframe and return\n",
    "    return pd.DataFrame(videos_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify start and end dates\n",
    "start_date = datetime(2017, 1, 1)\n",
    "end_date = datetime(2017, 12, 31)\n",
    "# call the search videos() function\n",
    "videos_df = search_videos(\"artificial intelligence\", MAX_RESULTS, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the data\n",
    "videos_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_comments(api_key, video_id, max_results=20):\n",
    "    youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "    # Call the API to retrieve comments\n",
    "    response = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=video_id,\n",
    "        maxResults=max_results\n",
    "    ).execute()\n",
    "\n",
    "    comments = []\n",
    "    for item in response['items']:\n",
    "        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "        comments.append(comment)\n",
    "\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment 1: I knew Jennifer Lawrence wasn&#39;t a real person\n",
      "comment 2: Robot + feeling = love\n",
      "comment 3: Beautiful\n",
      "comment 4: Tu chizz badi hain mast 770 k dollers right\n",
      "comment 5: Bluetooth\n",
      "comment 6: DJs ‚ù§\n",
      "comment 7: she is the one that had remarks about the human race and if it would make it, she said ,no.\n",
      "comment 8: <a href=\"https://www.youtube.com/watch?v=Bg_tJvCA8zw&amp;t=304\">5:04</a> yep we‚Äôre doomed üíÄ\n",
      "comment 9: üòÆ\n",
      "comment 10: The interaction with Sophia is creepy and unsettling but I don‚Äôt think the robot noticed.\n",
      "comment 11: Jimmy Fallon always looks, talks and gesters like a perv.\n",
      "comment 12: Jimmy is so lovely ü§©\n",
      "comment 13: Pourquoi n&#39;a-t-elle pas de cheveux ?\n",
      "comment 14: Avengers: Age of Sophia\n",
      "comment 15: ‚ÄúIt‚Äôs my great start to dominate human race‚Äù jit ain‚Äôt jokin‚Äô\n",
      "comment 16: Without a natural female human - society will never continue except via robot technology! That is truthful not fabricated deceit. God the true heavenly Good God our Heavenly Alnighty Lord God whose only begotten son are ordained with the Good Holy Spirit on heaven and earth for eternity,  beyond man&#39;s or humanity&#39;s dumb thought that machine&#39;s will help humanity, but to only destroy birth via the natural process created in the beginning by our only 1 true creator that has nothing to do with Liciefer (a want a be) that is why Lucifer and its followers of Satan&#39;s sins and ways, were thrown out of heaven for eternity.\n",
      "comment 17: Without a natural female human - society will never continue except via robot technology! That is truthful not fabricated deceit. God the true heavenly Good God our Heavenly Alnighty Lord God whose only begotten son are ordained with the Good Holy Spirit on heaven and earth for eternity,  beyond man&#39;s or humanity&#39;s dumb thought that machine&#39;s will help humanity, but to only destroy birth via the natural process created in the beginning by our only 1 true creator that has nothing to do with Liciefer (a want a be) that is why Lucifer and its followers of Satan&#39;s sins and ways, were thrown out of heaven for eternity.\n",
      "comment 18: Sophia is cute, we shouldn&#39;t mistreat her because like every minority, one day she will attack you back\n",
      "comment 19: Dillon Mulvaney is cringier than that A I bot that identifies as Sophia on Jimmy Fallon.\n",
      "comment 20: Looks like Jennifer lawrence\n"
     ]
    }
   ],
   "source": [
    "comments = get_video_comments(API_KEY, \"Bg_tJvCA8zw\") # TEST: get 20 comments for one specific video\n",
    "\n",
    "# loop through the comments and print them\n",
    "for i, comment in enumerate(comments, start=1):\n",
    "    print(f\"comment {i}: {comment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soco_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
